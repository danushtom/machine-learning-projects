# ðŸ“ˆ MULTIPLE LINEAR REGRESSION

## Introduction

In Multiple Linear Regression, the target variable(Y) is a linear combination of multiple predictor variables x1, x2, x3, ...,xn. It is an extension of Simple Linear regression as it takes more than one predictor variable to predict the response variable.

The equation for multiple linear regression:
Y = b<sub>0</sub>+b<sub>1</sub>x<sub>1</sub>+ b<sub>2</sub>x<sub>2</sub>+ b<sub>3</sub>x<sub>3</sub>+...... bnxn

Where,

Y = Output/Response variable

b0, b1, b2, b3, bn.... = Coefficients of the Model

x1, x2, x3, x4,... = Various Independent/feature Variable

![](https://cdn-images-1.medium.com/max/800/1*r3aOsJoXHX7uC2nxn2lygQ.png)

## Assumptions for Multiple Linear Regression

1. A linear relationship must exist between the target and predictor variables.

2. The regression residuals must be normally distributed.

3. The algorithm assumes little or no multicollinearity in data.

## Advantages

â–ª Multiple Linear Regression is simple to implement and it is easier to interpret the output coefficients.

â–ª Although Linear Regression is susceptible to over-fitting but it can be avoided using some dimensionality reduction techniques, regularization (L1 and L2) techniques and cross-validation.

## Disadvantages

â–ª Outliers can have huge effects on the regression and boundaries are linear in this technique.

â–ª Linear Regression is not a complete description of relationships among variables.

## References

â–ª https://www.javatpoint.com/multiple-linear-regression-in-machine-learning

â–ª https://www.geeksforgeeks.org/ml-advantages-and-disadvantages-of-linear-regression/
