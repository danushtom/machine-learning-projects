{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN for Fashion MNIST Clothing Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXTh0F1PKlPi"
      },
      "source": [
        "# CNN for Fashion MNIST Clothing Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64941Zo2TMib"
      },
      "source": [
        "##### **Convolutional Neural Network:** CNN is a class of deep neural networks, most commonly used for analyzing images.\n",
        "##### **Fashion MNIST Dataset:** Fashion MNIST is a dataset consisting of images with training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8DXTLu4XrDL"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqGDgCNjXJL7"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist \n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHwyQYykZMkg"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAnESWcWYC7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0be7ba-b34d-4c3d-d792-5392a2d16b57"
      },
      "source": [
        "(train_data,train_labels),(test_data,test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44d3k8e4NEoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c0651d-410c-41cc-d269-369d90892ab6"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyf92z3AZt2w"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0bqoN9tZnqo"
      },
      "source": [
        "train_data = train_data.reshape(-1,28,28,1)\n",
        "test_data = test_data.reshape(-1,28,28,1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ird6_YX6aEfR"
      },
      "source": [
        "train_data = train_data.astype('float32')/255    # Value of each pixel will range from 0 to 1 for improving learning rate of model\n",
        "test_data = test_data.astype('float32')/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tG90Fh5bi1J"
      },
      "source": [
        "# Using One Hot Encoding because we cannot work with categorical data directly\n",
        "train_labels_encoded = to_categorical(train_labels)\n",
        "test_labels_encoded = to_categorical(test_labels) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGdBgOggcU1N"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alHBYi66cQbD"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128,(3,3),input_shape=(28,28,1)))    # Training using 128 neurons and a 3x3 feature detector\n",
        "model.add(Activation('relu'))                         # Using ReLU activation function\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))              # Using Max Pooling to calculate the maximum value for each patch of the feature map\n",
        "model.add(Conv2D(128,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())                                  # To input 2D data and output data in 1D\n",
        "model.add(Dense(128))                                 # Adding dense layers\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))   # Using softmax activation function for the last layer so that the result could be interpreted as a probability distribution\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXKT6umdi-MB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f7a00e-17c1-4d2b-fd45-837a638d824e"
      },
      "source": [
        "model.fit(train_data,train_labels_encoded,batch_size=128,epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 37s 10ms/step - loss: 0.6604 - accuracy: 0.7607\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3074 - accuracy: 0.8887\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2615 - accuracy: 0.9065\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2259 - accuracy: 0.9182\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2150 - accuracy: 0.9205\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1935 - accuracy: 0.9306\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1732 - accuracy: 0.9366\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1611 - accuracy: 0.9412\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1417 - accuracy: 0.9501\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1286 - accuracy: 0.9525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fad401c96d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2OtJJm3kEh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2c30d6-0b16-4a9c-9058-f3c969ab1313"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_data, test_labels_encoded)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9053\n",
            "Test loss: 0.27368462085723877\n",
            "Test accuracy: 0.9053000211715698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yJro6AjlA3T"
      },
      "source": [
        "### Predicting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF4kxRS9k1Q7"
      },
      "source": [
        "predictions = model.predict(test_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONEpJjzslg_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6362817-0ddd-49c7-9980-eb483d3ac77f"
      },
      "source": [
        "# Printing the very first prediction\n",
        "print(np.argmax(np.round(predictions[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CgVC2a6mwVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a511c8fc-4efa-4d30-ed3b-9174a47f35ef"
      },
      "source": [
        "print(test_labels[0])   # This verifies that the prediction is correct"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2yPUEPFmPrb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "780d87f3-0e52-4df1-9991-5c1e5c9dcd3c"
      },
      "source": [
        "# Displaying the first image\n",
        "plt.imshow(test_data[0].reshape(28,28),cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6InquRx0OWo"
      },
      "source": [
        "### Getting the pkl File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQwXAM1Q0BzZ"
      },
      "source": [
        "import pickle\n",
        "weigh= model.get_weights();    pklfile= \"FashionMNISTClassifier.pkl\"\n",
        "fpkl= open(pklfile, 'wb')     \n",
        "pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "fpkl.close()"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}